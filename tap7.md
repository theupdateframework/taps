* TAP: 7
* Title: Conformance testing
* Version: 2
* Last-Modified: 27-June-2017
* Author: Vladimir Diaz, Sebastien Awwad
* Status: Draft
* Content-Type: text/markdown
* Created: 20-Jan-2017
* Post-History: 12-June-2017

# Abstract

((TODO: Motivation and Rationale sections are too redundant. Part of the
problem is that "Motivation" and "Rationale" seem to be interpreted as similar
things. The purpose of this TAP is explained many times, and so is the meaning
of passing all the tests.))

[Conformance testing](https://en.wikipedia.org/wiki/Conformance_testing)
can determine whether an implementation meets the requirements set by a given
specification.  At this point, no tool or set of data exists to help developers
and users affirm
that an implementation of an update system behaves according to the TUF
specification. Although the reference implementation contains
[unit tests](https://github.com/theupdateframework/tuf/tree/develop/tests)
that verify correct behavior (such as updating metadata in the expected order
and blocking known updater attacks) these unit tests only work within the
parameters of the reference implementation. This is problematic due to the
diversity of TUF implementations.

This proposal describes the design of a data configuration and format for
defining test cases that determine TUF compliance - most importantly, for
testing resilience to attacks against updaters.

The goals are to enable determination of whether or not an updater
implementation
conforms to the TUF specification, to interoperate with implementations in
diverse languages and environments, and to minimize the burden of such testing
on implementers.

# Motivation

Up to this point, adopters of TUF who had written an implementation could only test
for conformance by (1) verifying that metadata generated in some language X
matches that of the reference implementation, and/or (2) reproducing the unit
tests of the reference implementation in language X.  In the first case, only
the metadata generated by X can be said to conform to the specifications. The client
would still need to test for the expected behavior when the generated
metadata is updated.  In the second case, the implementation is said to
conform depending on how thoroughly the unit tests are reproduced in X.
There are bound to be inconsistencies between the two sets of unit tests. Any
improvements in TUF testing or changes to the program would require
implementers to add test code in parallel.

The ability to distribute test data accompanied by prescriptions for the
behavior expected from the updater processing each test case can ensure update
behavior as intended by the designers of TUF,
and, most importantly, ensure that an updater is secure against
the types of attacks and weaknesses listed in
[Section 1.5.2](https://github.com/theupdateframework/tuf/blob/6fde6222c9c6abf905ef4a56cf56fe35c4a85e14/docs/tuf-spec.txt#L124-L181)
of the TUF Specification. The official test cases should be publicly
available and usable by anyone who wishes to test an implementation.

If an updater performs as prescribed in every test case
((TODO: Decide on single term and be consistent:
test cases? test sets? scenarios? test conditions?)),
will help determine that the updater conforms to the TUF specification.

# Rationale

Developers need a convenient way of verifying whether an implementation
conforms to the TUF specification, affirming that the tested
implementation meets a recognized standard of secure operation.

The strategy for testing TUF conformance proposed in this TAP is to generate
sets of metadata and targets with the expectation that all implementations
should react to certain sets by successfully validating and updating, and all
implementations should react to other sets by rejecting the invalid metadata or
targets. Determining which data sets an implementation accepts and which it
rejects allows us to determine the implementation's TUF conformance, including
its resilience against the attacks listed in the TUF Specification (section
1.5.2).

For instance, a set of test data may provide metadata signed by an an untrusted
key to test whether or not the implementation will reject an untrusted signature.

While test cases may note the expected reason for an expected failure
to update, it is not expected that specific errors be raised; the only
prescription is that an updater correctly update or fail to update. TUF
conformance shouldn't depend on specific kinds of errors being communicated.

The validation behavior during testing should not vary significantly
from that in production so that test results can represent real updater
performance.


# Specification

The client updater implementation to be tested should operate as described in
the Client Workflow in Section 5.1 of the
[TUF Specification](https://github.com/theupdateframework/tuf/blob/develop/docs/tuf-spec.txt).
Tests will verify this behavior, determining whether or not the updater defends
against attacks described in Section 1.5.2 of the TUF Specification.

The updater will be expected to reject untrustworthy metadata and targets and
accept trustworthy metadata and targets. Control test cases will be used
alongside each test to verify correct behavior in the absence of an attack.

Tests will attempt endless data attacks, indefinite freeze attacks, replay
attacks, and a variety of others discussed in the TUF Specification. The full
listing of conformance tests and expected results will be provided in
documentation
[alongside the TUF Specification](https://github.com/theupdateframework/tuf/blob/develop/docs).

## Test Case Specification
Each test case will be specified with the following pieces of information:
- Description
- Expected Result
- Initial Trusted Metadata
- Repository Data
- Target to Install


### Description
The Description field will indicate the purpose of the test -- what attack it
expects to test the updater's defense against, or what problematic updater
behavior it checks for.

For example:
```
Test defense against metadata replay attacks: provide a snapshot role that
has a lower version than that already trusted by the client.
```

### Expected Result

This will be 'Success' or 'Failure'. If the value is 'Success', that will mean
that the client is expected to indicate that it was able to validate the
provided metadata and the target the updater was instructed to "install"
('Install Instruction') was deemed valid and OK to install. If the value is
'Failure', this means that the client is expected to indicate that the target
could not be installed - whether because an attack should be detected in the
metadata, or the target doesn't match values provided in the metadata,
or so on.

### Initial Trusted Metadata
This is the initial metadata the updater client will have and trust before
an update is attempted. TUF always requires some established root of trust to
be present in the updater client. The common case is generally a root.json file
that shipped with the updater. For testing purposes, this may also be a full
set of metadata, that which would have been validated in some previous update.

Metadata in the TUF specification's metadata format will be provided in a
directory, with the directory structure below. Data here should be converted
to whatever format the updater requires and delivered in the manner the updater
requires. he common case here
will be the path of a directory containing a trustworthy root.json
file.

This structure allows for optional multi-repository support per
[TAP 4](tap4.md). In the test data set intended for updaters that do not
support TAP 4, `map.json` will be excluded, and there will only be one
repository directory, named `test_repo`.

In most cases, the contents of the directory indicated as Initial Trusted
Metadata will simply be:
  ```
  - map.json // if TAP 4 is supported
  - keys.json
  - test_repo
           |-metadata
                |- root.json
  ```

But more may be provided:
  ```
  - map.json   // see TAP 4
  - keys.json
  - <repository_1_name>
              |- metadata
                    |- root.json
                    |- timestamp.json
                    |- snapshot.json
                    |- targets.json
                    |- <a delegated role>.json
                    |- <another delegated role>.json
                    |   ...
  - <repository_2_name>
              |- metadata
                    |- root.json
              // etc.
  ```

#### Keys for Re-Signing
The `keys.json` file will specify the keys used to generate the given metadata.
This information does not need to be used if the updater implementation uses
the same canonicalized JSON metadata format described in the TUF Specification
and used by the TUF Reference Implementation. If metadata has to be converted
and signed over a different format for the updater, these keys can be used to
re-sign the metadata and generate equivalent metadata in the new format.

The format of this dictionary of keys represented in `keys.json` is as follows.
(Note that the individual keys resemble ANYKEY_SCHEMA in the
[TUF format definitions](https://github.com/theupdateframework/tuf/blob/develop/tuf/formats.py))
The format below anticipates the optional use of
multiple repositories, as provided for in [TAP 4](tap4.md). If TAP 4
support is disabled, the only repository listed will be `test_repo`.
  ```javascript
  {
    <repository_1_name>: {
      <rolename_1>: [ // This role should be signed by these two keys:
        {'keytype': <type, e.g. 'ed25519'>,
         'keyid': <id string>,
         'keyval': {'public': <key string>, 'private': <key string>},
        },
        {'keytype': <type, e.g. 'ed25519'>,
         'keyid': <id string>,
         'keyval': {'public': <key string>, 'private': <key string>},
        }],
      <rolename_2>: [...]},

    <repository_2_name>: {...}
  }
  ```

  This listing indicates what key(s) should be used to sign each role
  in the test metadata. Sometimes (in the case of some attacks),
  these will not be the correct keys for the role.

Here's an excerpt from a particular example:
```javascript
{
  'imagerepo': {
    {'root': [{
      'keytype': 'ed25519',
      'keyid': '94c836f0c45168f0a437eef0e487b910f58db4d462ae457b5730a4487130f290',
      'keyval': {
        'public': 'f4ac8d95cfdf65a4ccaee072ba5a48e8ad6a0c30be6ffd525aec6bc078211033',
        'private': '879d244c6720361cf1f038a84082b08ac9cd586c32c1c9c6153f6db61b474957'}}]},
    {'timestamp': [{
      'keytype': 'ed25519',
      'keyid': '6fcd9a928358ad8ca7e946325f57ec71d50cb5977a8d02c5ab0de6765fef040a',
      'keyval': {
        'public': '97c1112bbd9047b1fdb50dd638bfed6d0639e0dff2c1443f5593fea40e30f654',
        'private': 'ef373ea36a633a0044bbca19a298a4100e7f353461d7fe546e0ec299ac1b659e'}}]},
    ...
    {'delegated_role1': [{
      'keytype': 'ed25519',
      'keyid': '8650aed05799a74f5febc9070c5d3e58d62797662d48062614b1ce0a643ee368',
      'keyval': {
        'public': 'c5a78db3f3ba96462525664e502f2e7893b81e7e270d75ffb9a6bb95b56857ca',
        'private': '134dc07435cd0d5a371d51ee938899c594c578dd0a3ab048aa70de5dd71f99f2'}}]}
  },
  'director': {
    {'root': [{
      ...
```


### Repository Data
This component of the test set is a directory of data - metadata and targets,
along with the keys used to sign the metadata - that should be made available
to the updater when it tries to update. This data should be treated normally by
the updater (not as initially-shipped, trusted data, that is).

It is similar to Initial Trusted Metadata in its form, but will lack a
`map.json` file (regardless of TAP 4 support), and will have `targets`
directories alongside each repository's `metadata` directory. For example:
  ```
  - keys.json
  - <repository_1_name>
              |- metadata
                    |- root.json
                    |- timestamp.json
                    |- snapshot.json
                    |- targets.json
                    |- <a delegated role>.json
                    |- <another delegated role>.json
                    |   ...
              |- targets
                    |- <some_target.img>
                    |-  ...
  - <repository_2_name>
              |- metadata
                    |- root.json
              // etc.
  ```
`keys.json` is as specified [above](#keys-for-re-signing).

Filepaths in the targets directory map directly to the filepaths
used to identify targets in the repository. For example, a target
identified in metadata with the filepath 'package1/tarball.tar' would
be found in 'targets/package1/tarball.tar'.



### Target to Install
The path of a target file that the updater should try to update/install, as
listed in the metadata provided. Filepaths are relative to the root of targets
directories. It is not necessary for the updater to have a notion of a
filesystem; this piece of information is intended to specify the target to
update to.






## Use of Test Data
Because different updaters may operate very differently, feeding the test data
to the client updater may require additional work. The
[Dealing with Implementation Restrictions](#dealing-with-implementation-restrictions)
section below addresses a variety of such scenarios in detail. Here are some
examples of what may be necessary:
 - move metadata or target files into the directory structure an updater
 implementation expects.
 - if, e.g., the updater doesn't have a notion of a filesystem, read the files
 the provided and distribute data to the updater in the manner the
 updater expects.
 - if the updater uses a different metadata format (for example, ASN.1/DER
 instead of canonical JSON -- or just a different arrangement in canonical
 JSON), translate metadata (Initial and Repository) from the format the Tester
 provides into the format the updater expects.
 - if the updater requires signatures to be over a different format, re-sign
 metadata after translating it.


### Re-Signing Converted Metadata
If an updater implementation uses a different metadata format than that
provided in test data, it becomes necessary to convert it for the updater's
use. Further, two situations arise depending on the behavior of the updater:
1. When the updater receives the converted metadata, it converts it back to
canonical JSON and checks the signatures in this (original) format.
2. When the updater receives the converted metadata, it will not convert it
back into canonical JSON, and will expect the signatures to be over the same
new format (foreign to TUF).

In the second case, the converted metadata must also be re-signed, so that the
updater will be able to correctly validate the metadata.

For this reason, a `keys.json` file is provided with any test case metadata.
This file,
[described above](#keys-for-re-signing), indicates which keys should be used to
sign each piece of metadata, if that metadata should need to be converted and
re-signed.

For an example of how such re-signing code might look, consider the JSON-to-DER
converter `convert_signed_metadata_to_der` employed by Uptane's TUF fork
[here](https://github.com/awwad/tuf/blob/36dbb7b8a800dab407fe9ab961155ef0a6d9f7c9/tuf/asn1_codec.py#L156-L352).


# Security Analysis

This TAP does not detract from existing security guarantees because it does not
propose architectural changes to the specification.


# Backwards Compatibility

This TAP does not introduce any backwards incompatibilities.


# Augmented Reference Implementation

Full test sets will be written after this TAP is accepted,
and that will be linked to from here.
Code employing them to test the TUF Reference Implementation will also be
provided, as a further guide for their use.


# Copyright

This document has been placed in the public domain.
